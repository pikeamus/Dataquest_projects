{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting House Sale Prices\n",
    "\n",
    "We're going to look at predicting house sale prices from a selection of other features (to be determined), using linear regression.\n",
    "\n",
    "Current status: Transforming features complete. Selecting features.\n",
    "\n",
    "## Reading the data\n",
    "\n",
    "Tab delimited file available from https://ww2.amstat.org/publications/jse/v19n3/decock/AmesHousing.txt with data dictionary https://ww2.amstat.org/publications/jse/v19n3/decock/DataDocumentation.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>526351010</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>526353030</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>527105010</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0      1  526301100           20        RL         141.0     31770   Pave   \n",
       "1      2  526350040           20        RH          80.0     11622   Pave   \n",
       "2      3  526351010           20        RL          81.0     14267   Pave   \n",
       "3      4  526353030           20        RL          93.0     11160   Pave   \n",
       "4      5  527105010           60        RL          74.0     13830   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour    ...     Pool Area Pool QC  Fence  \\\n",
       "0   NaN       IR1          Lvl    ...             0     NaN    NaN   \n",
       "1   NaN       Reg          Lvl    ...             0     NaN  MnPrv   \n",
       "2   NaN       IR1          Lvl    ...             0     NaN    NaN   \n",
       "3   NaN       Reg          Lvl    ...             0     NaN    NaN   \n",
       "4   NaN       IR1          Lvl    ...             0     NaN  MnPrv   \n",
       "\n",
       "  Misc Feature Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
       "0          NaN        0       5    2010       WD           Normal     215000  \n",
       "1          NaN        0       6    2010       WD           Normal     105000  \n",
       "2         Gar2    12500       6    2010       WD           Normal     172000  \n",
       "3          NaN        0       4    2010       WD           Normal     244000  \n",
       "4          NaN        0       3    2010       WD           Normal     189900  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import  LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('https://ww2.amstat.org/publications/jse/v19n3/decock/AmesHousing.txt',delimiter='\\t')\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to break up our data into a training and test set. We do this early so that we have a test set which hasn't influenced feature transformation and selection decisions. We do need to apply the same transformations to the test set though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Shuffles by default, uses np.random by default. Test is 25% of original.\n",
    "np.random.seed(1)\n",
    "train, test = train_test_split(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline version of process\n",
    "### Transform > Select > Train and test\n",
    "\n",
    "These three cells (will) contain the whole pipeline packaged into functions, to allow quick reuse. The reasoning behind the steps taken here are reproduced in full below. This pipeline structure mimics what a productionized version might look like, with each step available to receive new training data and data to be prepared for predictive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_features(trainset,testset):\n",
    "    \n",
    "    # Give new names to preserve originals\n",
    "    t_train, t_test = trainset, testset\n",
    "    \n",
    "    # Apply transformation to both sets, so we'll stick them in a list.\n",
    "    frames = [t_train,t_test]\n",
    "    \n",
    "    for f in frames:\n",
    "    \n",
    "        # Remove columns with more than 25% of values missing\n",
    "        f = f.drop(['Alley','Fireplace Qu','Pool QC','Fence','Misc Feature'],axis=1)\n",
    "        \n",
    "        # PID (postal id) and Order (observation number) aren't predictive. The others here leak info.\n",
    "        f = f.drop(['PID','Order','Sale Type','Sale Condition','Mo Sold','Yr Sold'],axis=1)\n",
    "        \n",
    "    \n",
    "        # Turning off chained assignment warning for the next step\n",
    "        pd.options.mode.chained_assignment = None  # default='warn'\n",
    "        \n",
    "        # Selecting columns numeric columns\n",
    "        cols = f.select_dtypes(include=['float64']).columns.tolist()\n",
    "        # Fillna on selected columns\n",
    "        f[cols] = f[cols].fillna(f[cols].mean())\n",
    "        \n",
    "        \n",
    "        # Removing nominal columns with high proportion of nulls.\n",
    "        f = f.drop(['Street', 'Land Contour', 'Condition 2', 'Roof Matl', 'Heating', 'Central Air'],axis=1)\n",
    "        \n",
    "        # Filling nulls for nominal columns from which I want to create dummies.\n",
    "        f['Garage Type'].fillna('None',inplace=True)\n",
    "        f['Mas Vnr Type'].fillna('Unknown',inplace=True)\n",
    "        \n",
    "        # Creating dummies of nominals\n",
    "        nominals = ['MS SubClass', 'MS Zoning', 'Lot Config', 'Neighborhood', 'Condition 1', 'Bldg Type', 'House Style', \n",
    "                    'Roof Style', 'Exterior 1st', 'Exterior 2nd', 'Mas Vnr Type', 'Foundation', 'Garage Type']\n",
    "        \n",
    "        # Change to category type\n",
    "        for n in nominals:\n",
    "            f[n] = f[n].astype('category')\n",
    "\n",
    "        # Get dummy cols and combine to dataset\n",
    "        dummy_cols = pd.get_dummies(f[nominals])\n",
    "        f = pd.concat([f,dummy_cols],axis=1)\n",
    "        # Drop the original columns\n",
    "        f.drop(nominals,axis=1,inplace=True)\n",
    "        \n",
    "        # Drop ordinals that are largely one value\n",
    "        f = f.drop(['Garage Qual','Garage Qual','Bsmt Cond'],axis=1)\n",
    "\n",
    "        # Map convenient ordinals to values\n",
    "        m_vals = {'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,np.nan:0}\n",
    "        cols = ['Exter Qual','Exter Cond','Bsmt Qual','Heating QC','Kitchen Qual']\n",
    "        f[m_cols] = f[cols].applymap(m_vals.get)\n",
    "    \n",
    "    return t_train, t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_features(in_df):\n",
    "    selected_train = in_df[['Gr Liv Area','SalePrice']] \n",
    "    return selected_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_test(inframe=data):\n",
    "    lrm = LinearRegression()\n",
    "    train_data = select_features(inframe)\n",
    "    \n",
    "    mean_s_errors = cross_val_score(lrm,\n",
    "                                    train_data.drop('SalePrice',axis=1),\n",
    "                                    train_data['SalePrice'],\n",
    "                                    scoring='neg_mean_squared_error',\n",
    "                                    cv=10)\n",
    "    # Root mean squared errors for each fold\n",
    "    r_ms_errors = [abs(m)**(1/2) for m in mean_s_errors]\n",
    "    \n",
    "    # Average root mean squared error across all folds\n",
    "    avg_rms_error = np.mean(r_ms_errors)\n",
    "    \n",
    "    return r_ms_errors, avg_rms_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55364.966905101006, 67414.767057828198, 51652.028143302261, 61142.428190830913, 46974.79071976852, 69710.357300782242, 52492.991532255481, 61806.901095779387, 52299.554294257054, 47351.675966573712] \n",
      "\n",
      "56621.0461206\n"
     ]
    }
   ],
   "source": [
    "rmses, armse = train_and_test()\n",
    "print(rmses,'\\n')\n",
    "print(armse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Cells\n",
    "\n",
    "## Transformations\n",
    "\n",
    "### Numerical nulls and data leaks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alley           2054\n",
       "Fireplace Qu    1066\n",
       "Pool QC         2185\n",
       "Fence           1778\n",
       "Misc Feature    2117\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First looking for features with large numbers of nulls (more than 25%)\n",
    "# We'll remove these wholesale, assuming nothing too vital jumps out.\n",
    "\n",
    "num_val_counts = train.isnull().sum()\n",
    "num_val_counts[num_val_counts > 0.25*train.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Looks ok, so dropping these. Starting new set for transformed data, in case we want to check data again.\n",
    "t_train = train[num_val_counts[num_val_counts < 0.25*train.shape[0]].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2197 entries, 533 to 1061\n",
      "Data columns (total 22 columns):\n",
      "Lot Frontage      1835 non-null float64\n",
      "Mas Vnr Type      2175 non-null object\n",
      "Mas Vnr Area      2175 non-null float64\n",
      "Bsmt Qual         2130 non-null object\n",
      "Bsmt Cond         2130 non-null object\n",
      "Bsmt Exposure     2128 non-null object\n",
      "BsmtFin Type 1    2130 non-null object\n",
      "BsmtFin SF 1      2196 non-null float64\n",
      "BsmtFin Type 2    2129 non-null object\n",
      "BsmtFin SF 2      2196 non-null float64\n",
      "Bsmt Unf SF       2196 non-null float64\n",
      "Total Bsmt SF     2196 non-null float64\n",
      "Electrical        2196 non-null object\n",
      "Bsmt Full Bath    2196 non-null float64\n",
      "Bsmt Half Bath    2196 non-null float64\n",
      "Garage Type       2077 non-null object\n",
      "Garage Yr Blt     2075 non-null float64\n",
      "Garage Finish     2075 non-null object\n",
      "Garage Cars       2196 non-null float64\n",
      "Garage Area       2196 non-null float64\n",
      "Garage Qual       2075 non-null object\n",
      "Garage Cond       2075 non-null object\n",
      "dtypes: float64(11), object(11)\n",
      "memory usage: 394.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Reassign to drop the four missing columns\n",
    "num_val_counts = t_train.isnull().sum()\n",
    "\n",
    "# Now we'll take a look at columns with fewer but still non-zero nulls.\n",
    "t_train[num_val_counts[num_val_counts > 0].index].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data dictionary we can see all the numeric columns here are ordinal or continuous, so we can replace nulls in these columns with the mean for the column without creating nonsense values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>534</td>\n",
       "      <td>531363010</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>9605</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>803</td>\n",
       "      <td>906203120</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>14684</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>271900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>956</td>\n",
       "      <td>916176030</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>69.549319</td>\n",
       "      <td>14375</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>NoSeWa</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>COD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>137500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>460</td>\n",
       "      <td>528180130</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>6472</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>248500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>487</td>\n",
       "      <td>528290030</td>\n",
       "      <td>80</td>\n",
       "      <td>RL</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>9734</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>167000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "533    534  531363010           20        RL     80.000000      9605   Pave   \n",
       "802    803  906203120           20        RL     90.000000     14684   Pave   \n",
       "955    956  916176030           20        RL     69.549319     14375   Pave   \n",
       "459    460  528180130          120        RL     48.000000      6472   Pave   \n",
       "486    487  528290030           80        RL     61.000000      9734   Pave   \n",
       "\n",
       "    Lot Shape Land Contour Utilities    ...     Enclosed Porch 3Ssn Porch  \\\n",
       "533       Reg          Lvl    AllPub    ...                  0          0   \n",
       "802       IR1          Lvl    AllPub    ...                  0          0   \n",
       "955       IR1          Lvl    NoSeWa    ...                  0          0   \n",
       "459       Reg          Lvl    AllPub    ...                  0          0   \n",
       "486       IR1          Lvl    AllPub    ...                  0          0   \n",
       "\n",
       "    Screen Porch Pool Area Misc Val Mo Sold Yr Sold  Sale Type  \\\n",
       "533            0         0        0       4    2009        WD    \n",
       "802            0         0        0       6    2009        WD    \n",
       "955          233         0        0       1    2009        COD   \n",
       "459            0         0        0       4    2009        WD    \n",
       "486            0         0        0       5    2009        WD    \n",
       "\n",
       "     Sale Condition  SalePrice  \n",
       "533          Normal     159000  \n",
       "802          Normal     271900  \n",
       "955         Abnorml     137500  \n",
       "459          Normal     248500  \n",
       "486          Normal     167000  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turning off chained assignment warning\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Select columns to replace\n",
    "cols = t_train.select_dtypes(include=['float64']).columns.tolist()\n",
    "\n",
    "# Fillna on selected columns\n",
    "t_train[cols] = t_train[cols].fillna(t_train[cols].mean())\n",
    "\n",
    "t_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll return to the string fields separately. Let's briefly take a diversion to remove columns that may leak info about the final sale (i.e. columns that contain data we won't have when making a prediction, like the Sale Month and Year). We'll drop all of these. Additionally, reading the documentation we can see that PID and Order are not going to be useful for us so we'll drop those too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_cols = ['Sale Type','Sale Condition','Mo Sold','Yr Sold','PID','Order']\n",
    "t_train = t_train.drop(leak_cols,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nominal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS SubClass \n",
      " % of rows with single value  0.371415566682 \n",
      " unique vals  15 \n",
      "\n",
      "MS Zoning \n",
      " % of rows with single value  0.77560309513 \n",
      " unique vals  7 \n",
      "\n",
      "Street \n",
      " % of rows with single value  0.995903504779 \n",
      " unique vals  2 \n",
      "\n",
      "Land Contour \n",
      " % of rows with single value  0.902594446973 \n",
      " unique vals  4 \n",
      "\n",
      "Lot Config \n",
      " % of rows with single value  0.726900318616 \n",
      " unique vals  5 \n",
      "\n",
      "Neighborhood \n",
      " % of rows with single value  0.147473827947 \n",
      " unique vals  28 \n",
      "\n",
      "Condition 1 \n",
      " % of rows with single value  0.862084660901 \n",
      " unique vals  9 \n",
      "\n",
      "Condition 2 \n",
      " % of rows with single value  0.989986345016 \n",
      " unique vals  8 \n",
      "\n",
      "Bldg Type \n",
      " % of rows with single value  0.826126536186 \n",
      " unique vals  5 \n",
      "\n",
      "House Style \n",
      " % of rows with single value  0.511151570323 \n",
      " unique vals  8 \n",
      "\n",
      "Roof Style \n",
      " % of rows with single value  0.789713245335 \n",
      " unique vals  6 \n",
      "\n",
      "Roof Matl \n",
      " % of rows with single value  0.985889849795 \n",
      " unique vals  8 \n",
      "\n",
      "Exterior 1st \n",
      " % of rows with single value  0.359581247155 \n",
      " unique vals  16 \n",
      "\n",
      "Exterior 2nd \n",
      " % of rows with single value  0.35593991807 \n",
      " unique vals  17 \n",
      "\n",
      "Mas Vnr Type \n",
      " % of rows with single value  0.594902139281 \n",
      " unique vals  6 \n",
      "\n",
      "Foundation \n",
      " % of rows with single value  0.455621301775 \n",
      " unique vals  6 \n",
      "\n",
      "Heating \n",
      " % of rows with single value  0.98224852071 \n",
      " unique vals  6 \n",
      "\n",
      "Central Air \n",
      " % of rows with single value  0.93218024579 \n",
      " unique vals  2 \n",
      "\n",
      "Garage Type \n",
      " % of rows with single value  0.599908966773 \n",
      " unique vals  7 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Columns listed as nominal in the dictionary (minus those we've already dropped)\n",
    "nominals = ['MS SubClass','MS Zoning','Street','Land Contour','Lot Config',\n",
    "            'Neighborhood','Condition 1','Condition 2','Bldg Type','House Style',\n",
    "            'Roof Style','Roof Matl','Exterior 1st','Exterior 2nd','Mas Vnr Type',\n",
    "            'Foundation','Heating','Central Air','Garage Type']\n",
    "\n",
    "# A couple of stats on each column. Also stored in dictionary.\n",
    "noms = {}\n",
    "\n",
    "for n in nominals:\n",
    "    counts = t_train[n].value_counts(dropna=False)\n",
    "    \n",
    "    # Dictionary will contain % of rows belonging to the most common category\n",
    "    noms[n] = [counts.max()/counts.sum(),counts.shape[0]]\n",
    "    print(n,'\\n % of rows with single value ',counts.max()/counts.sum(),'\\n unique vals ',counts.shape[0],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns where a high number of rows have the same value won't have much use in the model, so can probably be discounted. We'll drop those here. I'm picking a threshold of 90% here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 71)\n",
      "Street\n",
      "Land Contour\n",
      "Condition 2\n",
      "Roof Matl\n",
      "Heating\n",
      "Central Air\n",
      "(2197, 65)\n"
     ]
    }
   ],
   "source": [
    "print(t_train.shape)\n",
    "for n in noms:\n",
    "    if noms[n][0] > 0.9:\n",
    "        print(n)\n",
    "        # Drop from our transformed data and also from nominals list\n",
    "        t_train.drop(n,axis=1,inplace=True)\n",
    "        nominals.remove(n)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll think about whether or not we want to transform the other nominal columns into dummy numerical columns. Scanning back over the list a few cells up, there are a few columns with a number of categories but they tend to be fairly important. The numbers aren't in the hundreds, so I'm inclined to keep them all. We do need to deal with nulls though, as null values throw an error when we try to change it to a category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MS SubClass       0\n",
       "MS Zoning         0\n",
       "Lot Config        0\n",
       "Neighborhood      0\n",
       "Condition 1       0\n",
       "Bldg Type         0\n",
       "House Style       0\n",
       "Roof Style        0\n",
       "Exterior 1st      0\n",
       "Exterior 2nd      0\n",
       "Mas Vnr Type     22\n",
       "Foundation        0\n",
       "Garage Type     120\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train[nominals].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attchd     1318\n",
       "Detchd      568\n",
       "BuiltIn     137\n",
       "NaN         120\n",
       "Basment      28\n",
       "2Types       17\n",
       "CarPort       9\n",
       "Name: Garage Type, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train['Garage Type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None       1307\n",
       "BrkFace     658\n",
       "Stone       190\n",
       "NaN          22\n",
       "BrkCmn       19\n",
       "CBlock        1\n",
       "Name: Mas Vnr Type, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train['Mas Vnr Type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data dictionary lists the NaN garage types as 'no garage'. I'm inclined to trust the dictionary, so I'll fill those with a string 'None'. For Mas Vnr Type, none is already an option and the dictionary doesn't mention nulls, so I'll replace those with Unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_data['Garage Type'].fillna('None',inplace=True)\n",
    "t_data['Mas Vnr Type'].fillna('Unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MS SubClass', 'MS Zoning', 'Lot Config', 'Neighborhood', 'Condition 1', 'Bldg Type', 'House Style', 'Roof Style', 'Exterior 1st', 'Exterior 2nd', 'Mas Vnr Type', 'Foundation', 'Garage Type']\n"
     ]
    }
   ],
   "source": [
    "print(nominals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to category type\n",
    "for n in nominals:\n",
    "    t_train[n] = t_train[n].astype('category')\n",
    "\n",
    "# Get dummy cols and combine to dataset\n",
    "dummy_cols = pd.get_dummies(t_train[nominals])\n",
    "t_train = pd.concat([t_train,dummy_cols],axis=1)\n",
    "\n",
    "# Drop the original columns\n",
    "t_train.drop(nominals,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal string columns\n",
    "\n",
    "String columns with a meaningful order will be turned mapped ot numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lot Shape',\n",
       " 'Utilities',\n",
       " 'Land Slope',\n",
       " 'Exter Qual',\n",
       " 'Exter Cond',\n",
       " 'Bsmt Qual',\n",
       " 'Bsmt Cond',\n",
       " 'Bsmt Exposure',\n",
       " 'BsmtFin Type 1',\n",
       " 'BsmtFin Type 2',\n",
       " 'Heating QC',\n",
       " 'Electrical',\n",
       " 'Kitchen Qual',\n",
       " 'Functional',\n",
       " 'Garage Finish',\n",
       " 'Garage Qual',\n",
       " 'Garage Cond',\n",
       " 'Paved Drive']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dictionary, eight of these columns use a standard scale of Excellent to Poor (5 steps - some with nulls where the property doesn't have the item rated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Exter Qual  - Non-null values: 2197\n",
      "TA    1321\n",
      "Gd     760\n",
      "Ex      91\n",
      "Fa      25\n",
      "Name: Exter Qual, dtype: int64\n",
      "\n",
      " Exter Cond  - Non-null values: 2197\n",
      "TA    1922\n",
      "Gd     218\n",
      "Fa      46\n",
      "Ex       8\n",
      "Po       3\n",
      "Name: Exter Cond, dtype: int64\n",
      "\n",
      " Bsmt Qual  - Non-null values: 2130\n",
      "Gd     930\n",
      "TA     929\n",
      "Ex     198\n",
      "Fa      71\n",
      "NaN     67\n",
      "Po       2\n",
      "Name: Bsmt Qual, dtype: int64\n",
      "\n",
      " Bsmt Cond  - Non-null values: 2130\n",
      "TA     1970\n",
      "Gd       83\n",
      "Fa       72\n",
      "NaN      67\n",
      "Po        3\n",
      "Ex        2\n",
      "Name: Bsmt Cond, dtype: int64\n",
      "\n",
      " Heating QC  - Non-null values: 2197\n",
      "Ex    1126\n",
      "TA     632\n",
      "Gd     365\n",
      "Fa      71\n",
      "Po       3\n",
      "Name: Heating QC, dtype: int64\n",
      "\n",
      " Kitchen Qual  - Non-null values: 2197\n",
      "TA    1105\n",
      "Gd     870\n",
      "Ex     164\n",
      "Fa      57\n",
      "Po       1\n",
      "Name: Kitchen Qual, dtype: int64\n",
      "\n",
      " Garage Qual  - Non-null values: 2075\n",
      "TA     1957\n",
      "NaN     122\n",
      "Fa       93\n",
      "Gd       18\n",
      "Po        5\n",
      "Ex        2\n",
      "Name: Garage Qual, dtype: int64\n",
      "\n",
      " Garage Cond  - Non-null values: 2075\n",
      "TA     1993\n",
      "NaN     122\n",
      "Fa       55\n",
      "Po       13\n",
      "Gd       11\n",
      "Ex        3\n",
      "Name: Garage Cond, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols = ['Exter Qual','Exter Cond','Bsmt Qual','Bsmt Cond','Heating QC','Kitchen Qual','Garage Qual','Garage Cond']\n",
    "\n",
    "for c in cols:\n",
    "    print('\\n',c,' - Non-null values:',t_train[t_train[c].isnull() == False].shape[0])\n",
    "    print(t_train[c].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Garage Quality and Condition are both ~95% one value, with nulls being the second most common category. This means both offer very little to the model, so aren't likely worth transforming. Basement condiditon is similar. External condition is marginal but I'm inclined to include it as I feel it should have a noticable predictive effect.\n",
    "\n",
    "For the others, I'll use a map to transform the categories into values. 5 = Excellent, 1 = Poor (null = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Exter Qual  Exter Cond  Bsmt Qual  Heating QC  Kitchen Qual\n",
      "533           4           3          4           5             4\n",
      "802           4           3          4           4             4\n",
      "955           3           3          3           4             4\n",
      "459           5           3          5           5             5\n",
      "486           4           3          4           5             4\n"
     ]
    }
   ],
   "source": [
    "t_train = t_train.drop(['Garage Qual','Garage Qual','Bsmt Cond'],axis=1)\n",
    "\n",
    "m_vals = {'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,np.nan:0}\n",
    "m_cols = ['Exter Qual','Exter Cond','Bsmt Qual','Heating QC','Kitchen Qual']\n",
    "\n",
    "t_train[m_cols] = t_train[m_cols].applymap(m_vals.get)\n",
    "print(t_train[m_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Lot Shape  - Non-null values: 2197\n",
      "Reg    1389\n",
      "IR1     737\n",
      "IR2      60\n",
      "IR3      11\n",
      "Name: Lot Shape, dtype: int64\n",
      "\n",
      " Utilities  - Non-null values: 2197\n",
      "AllPub    2194\n",
      "NoSewr       2\n",
      "NoSeWa       1\n",
      "Name: Utilities, dtype: int64\n",
      "\n",
      " Land Slope  - Non-null values: 2197\n",
      "Gtl    2091\n",
      "Mod      93\n",
      "Sev      13\n",
      "Name: Land Slope, dtype: int64\n",
      "\n",
      " Bsmt Exposure  - Non-null values: 2128\n",
      "No     1406\n",
      "Av      325\n",
      "Gd      227\n",
      "Mn      170\n",
      "NaN      69\n",
      "Name: Bsmt Exposure, dtype: int64\n",
      "\n",
      " BsmtFin Type 1  - Non-null values: 2130\n",
      "GLQ    664\n",
      "Unf    644\n",
      "ALQ    332\n",
      "Rec    204\n",
      "BLQ    179\n",
      "LwQ    107\n",
      "NaN     67\n",
      "Name: BsmtFin Type 1, dtype: int64\n",
      "\n",
      " BsmtFin Type 2  - Non-null values: 2129\n",
      "Unf    1871\n",
      "Rec      76\n",
      "LwQ      69\n",
      "NaN      68\n",
      "BLQ      52\n",
      "ALQ      38\n",
      "GLQ      23\n",
      "Name: BsmtFin Type 2, dtype: int64\n",
      "\n",
      " Electrical  - Non-null values: 2196\n",
      "SBrkr    2020\n",
      "FuseA     131\n",
      "FuseF      38\n",
      "FuseP       6\n",
      "Mix         1\n",
      "NaN         1\n",
      "Name: Electrical, dtype: int64\n",
      "\n",
      " Functional  - Non-null values: 2197\n",
      "Typ     2037\n",
      "Min2      58\n",
      "Min1      49\n",
      "Mod       27\n",
      "Maj1      17\n",
      "Maj2       7\n",
      "Sev        1\n",
      "Sal        1\n",
      "Name: Functional, dtype: int64\n",
      "\n",
      " Garage Finish  - Non-null values: 2075\n",
      "Unf    902\n",
      "RFn    629\n",
      "Fin    544\n",
      "NaN    122\n",
      "Name: Garage Finish, dtype: int64\n",
      "\n",
      " Paved Drive  - Non-null values: 2197\n",
      "Y    1986\n",
      "N     161\n",
      "P      50\n",
      "Name: Paved Drive, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remaining few ordinal columns\n",
    "cols = ['Lot Shape','Utilities','Land Slope','Bsmt Exposure','BsmtFin Type 1','BsmtFin Type 2',\n",
    "        'Electrical','Functional','Garage Finish','Paved Drive']\n",
    "\n",
    "for c in cols:\n",
    "    print('\\n',c,' - Non-null values:',t_train[t_train[c].isnull() == False].shape[0])\n",
    "    print(t_train[c].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm less comfortable applying a mapping to these categories, as it's less obvious how to weight each value. Instead, I will convert each to dummy variables, as I did with the nominal columns. I can revisit this later and see if I can get any better results. I will drop utilities and land slope though, due to overwhelming proportion of rows belonging to a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train.drop(['Utilities','Land Slope'],axis=1,inplace=True)\n",
    "\n",
    "ordinals = ['Lot Shape','Bsmt Exposure','BsmtFin Type 1','BsmtFin Type 2',\n",
    "        'Electrical','Functional','Garage Finish','Paved Drive']\n",
    "\n",
    "# Change to category type\n",
    "for n in ordinals:\n",
    "    t_train[n] = t_train[n].astype('category',errors='ignore')\n",
    "\n",
    "# Get dummy cols and combine to dataset\n",
    "dummy_cols = pd.get_dummies(t_train[ordinals])\n",
    "t_train = pd.concat([t_train,dummy_cols],axis=1)\n",
    "\n",
    "# Drop the original columns\n",
    "t_train.drop(ordinals,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STATUS - ABOVE CELL NOT YET ADDED TO FUNCTION. OTHERWISE, READY TO MOVE TO FEATURE SELECTION"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
